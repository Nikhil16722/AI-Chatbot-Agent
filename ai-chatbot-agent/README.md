# ğŸ¤– AI Chatbot Agent â€” Powered by FastAPI & Ollama

![Chatbot Preview](app/static/niki0.png)

## ğŸŒŸ Overview

**AI Chatbot Agent** is a smart, interactive chatbot built with **FastAPI**, **HTML**, **CSS**, and **JavaScript** that connects to a **local Ollama LLM** (Large Language Model) to generate natural language responses â€” fully offline.

It features:

* ğŸ§  Real AI-generated responses (no hardcoded replies)
* âš¡ FastAPI backend for smooth async processing
* ğŸ¨ Beautiful UI with animated glass effect
* ğŸŒ… Fixed aesthetic background image
* ğŸ’¬ â€œThinkingâ€¦â€ typing simulation
* ğŸ–¥ï¸ Completely offline (works with Ollama locally)

---

## ğŸš€ Tech Stack

| Layer         | Technology Used                          | Purpose                                        |
| ------------- | ---------------------------------------- | ---------------------------------------------- |
| **Backend**   | [FastAPI](https://fastapi.tiangolo.com/) | Handles API routes for chat messages           |
| **Frontend**  | HTML, CSS, JavaScript                    | Interactive chat interface                     |
| **AI Engine** | [Ollama](https://ollama.ai)              | Runs local LLMs (like Llama 3, Phi-3, Mistral) |
| **Runtime**   | Python 3.10+                             | Application base                               |
| **Server**    | [Uvicorn](https://www.uvicorn.org/)      | ASGI server for running FastAPI                |

---

## ğŸ§© Project Structure

```
ai-chatbot-agent/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # FastAPI backend logic
â”‚   â”œâ”€â”€ chat.py               # (Optional) Chat utilities
â”‚   â”œâ”€â”€ ingest.py             # (Optional) Knowledge ingestion
â”‚   â”œâ”€â”€ retrieval.py          # (Optional) Vector search
â”‚   â”œâ”€â”€ utils.py              # Helper functions
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ index.html        # Chat UI
â”‚   â”‚   â”œâ”€â”€ style.css         # Front-end styling
â”‚   â”‚   â”œâ”€â”€ script.js         # Client-side logic
â”‚   â”‚   â””â”€â”€ niki.jpg          # Background image
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ data/                     # Sample text / knowledge data
â”‚   â”œâ”€â”€ ai_intro.txt
â”‚   â”œâ”€â”€ company_info.txt
â”‚   â””â”€â”€ notes.md
â”‚
â”œâ”€â”€ requirements.txt          # Required Python packages
â”œâ”€â”€ Dockerfile                # (Optional) For containerization
â”œâ”€â”€ .env                      # Environment config
â”œâ”€â”€ README.md                 # Documentation
â””â”€â”€ run.sh                    # Script to launch app
```

---

## âš™ï¸ Installation & Setup

### ğŸ§± Prerequisites

* Python 3.10 or above
* [Ollama](https://ollama.ai) installed and running locally
* Any modern browser

---

### ğŸ§© 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your-username/ai-chatbot-agent.git
cd ai-chatbot-agent
```

---

### ğŸ§© 2ï¸âƒ£ Create a virtual environment

```bash
python -m venv venv
venv\Scripts\activate      # On Windows
# OR
source venv/bin/activate   # On macOS/Linux
```

---

### ğŸ§© 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

### ğŸ§© 4ï¸âƒ£ Check Ollama

Run these commands to verify Ollama is active:

```bash
ollama list
ollama serve
```

âœ… You should see:
`Listening on 127.0.0.1:11434`

Download a model (if not already):

```bash
ollama pull llama3
```

Test it:

```bash
ollama run llama3 "Hello!"
```

---

### ğŸ§© 5ï¸âƒ£ Run the Chatbot

```bash
uvicorn app.main:app --reload
```

Now visit ğŸ‘‰ **[http://127.0.0.1:8000](http://127.0.0.1:8000)**

---

## ğŸ’¬ How It Works

1. The user types a message in the chatbox.
2. The message is sent to FastAPI via `/chat` endpoint.
3. FastAPI calls Ollama locally (`ollama run llama3 "message"`).
4. Ollama generates a **real AI response**.
5. The frontend shows a typing animation ("ğŸ¤– Thinking...") before displaying the reply.
6. The conversation updates dynamically with a clean UI.

---

## ğŸ–¼ï¸ UI Features

* ğŸŒ… Background image (fixed, full screen)
* ğŸ’  Glassmorphism chat window
* âœ¨ Smooth hover and shadow transitions
* ğŸ’¬ Real-time message display
* â³ Typing/Thinking effect

---

## ğŸ“¦ requirements.txt

```txt
fastapi
uvicorn
requests
pydantic
python-dotenv
```

---

## ğŸ§  Example Models to Use with Ollama

You can use any of these models:

| Model   | Command               | Size   | Description                     |
| ------- | --------------------- | ------ | ------------------------------- |
| Llama 3 | `ollama pull llama3`  | ~4.7GB | Great general-purpose model     |
| Phi 3   | `ollama pull phi3`    | ~2.5GB | Lightweight, fast for small PCs |
| Mistral | `ollama pull mistral` | ~4.1GB | Good for reasoning and Q&A      |
| Gemma   | `ollama pull gemma`   | ~3GB   | Smaller, conversational tone    |

To switch models, just edit `main.py` here:

```python
["ollama", "run", "llama3", user_message]
```

â†’ replace `"llama3"` with `"phi3"`, `"mistral"`, etc.

---

## ğŸ§‘â€ğŸ’» Example Interaction

**User:**

> What is Python?

**Bot:**

> Python ğŸ is a versatile, beginner-friendly programming language used in AI, data analytics, and automation.

**User:**

> Tell me about SQL

**Bot:**

> SQL ğŸ’¾ helps you manage and query data efficiently in relational databases.

---

## ğŸ§  Future Enhancements

* ğŸ§© Add memory (context retention)
* ğŸ“š Connect to your own documents or knowledge base
* ğŸ—£ï¸ Add speech-to-text and voice replies
* ğŸŒ Deploy online using Render / Vercel / Railway
* ğŸ’¾ Integrate database logging for chat history

---

## ğŸ§‘â€ğŸ’» Author

**ğŸ‘¤ Nikhil Lingala**
ğŸ’» *AI | Data Analytics | Automation Enthusiast*
ğŸ“« [LinkedIn](https://www.linkedin.com/in/nikhil-lingala-a26030266/) |

---

## ğŸª¶ License

This project is licensed under the **MIT License** â€” free to use, modify, and distribute.

---

### ğŸ’¡ Pro Tip

> If you want Ollama to start automatically every time you launch your chatbot:
>
> ```bash
> ollama serve --detach
> ```
>
> That keeps it running silently in the background ğŸš€

---
